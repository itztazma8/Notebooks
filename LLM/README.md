## A Custom LLM
### Tokenizer
This is a basic but custom tokenizer with all the necessary functions (encode and decode). The dataset that has been used is the *[Poetry Dataset]*(https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems). 
